{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stock-guyana",
   "metadata": {},
   "source": [
    "# Image Pre processing\n",
    "Because noone wants 50+ Gb of image data\n",
    "\n",
    "* This notebook will process the images so that to crops out the interesting parts and saves it as numpy arrays, ready to be loaded into the analysis scripts of your chouce\n",
    "* Normalisation to white source is done as if the source was uniform\n",
    "\n",
    "* The script expects youd data to be organised in the following format:\n",
    "```\n",
    "Root_data_folder    \n",
    "│\n",
    "└───Substrate_1\n",
    "│   └───2  \n",
    "│       └───oc\n",
    "│       │   │   LED_power_suply.csv\n",
    "│       │   │   source_meter.csv\n",
    "│       │   └───camera\n",
    "│       │       │     camera_setting_dump.txt\n",
    "│       │       │     exposure_list.csv\n",
    "│       │       │     OC_LED=2.580_0.tif\n",
    "│       │       │     OC_LED=2.580_1.tif\n",
    "│       │       │     ...\n",
    "│       └───sc\n",
    "│       │   │   LED_power_suply.csv\n",
    "│       │   │   ...\n",
    "│       └───vsweep   \n",
    "│       │...\n",
    "└───Substrate_2\n",
    "│   │   ...\n",
    "│    ...\n",
    "└───white\n",
    "│   │   ...\n",
    "```\n",
    "* Not all the csv/txt files need to exist, but if they exist in the above format, they will be copied over in the processed folder\n",
    "* The processed images are saved as numpy files\n",
    "    * file name is in the format <em>sourcemeter</em>/<em>powermeter measured flux</em>\n",
    "\n",
    "### Some instructions: \n",
    "* Please run each cell in order, following the instructions\n",
    "* Press cntrl+enter to run a cell\n",
    "* When prompted enter information into the feilds and press enter\n",
    "* If you go back and re run a cell, that's fine but you have to run every cell after that again, and in order\n",
    "\n",
    "This might break if all these files are not there! If you want to edit this code definately go ahead, a bunch of the functions live in seperate .py files, BUT please make a copy!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-science",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some imports:\n",
    "from external_imports import *\n",
    "from image_process import *\n",
    "from general_data_process import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-africa",
   "metadata": {},
   "source": [
    "### Data/save path\n",
    "* Edit to add where your data lives and where the saved data is going to live:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r\"\"\n",
    "savepath = r\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-result",
   "metadata": {},
   "source": [
    "### White reference\n",
    "* First thing we need to do is determine the center of the beam spot, for which we will use the 'white reference'\n",
    "* Make the rectangle bound your white reference, and then press save 'crop size'\n",
    "* This calculates where the center of the distribution is, which the whole calibration hinges on so be careful!\n",
    "* Since we just need the center, what you choose as the 'edge' is not important as long as you are consistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-taiwan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filenames for white ref + bg:\n",
    "whitefiles = find_tif(datapath+r\"\\white\\camera\")\n",
    "whitereffiles = find_tif(datapath+r\"\\white\\camera\\refs\")\n",
    "\n",
    "# Open and average\n",
    "white = averager(datapath+r\"\\white\\camera\", whitefiles)\n",
    "white_ref = averager(datapath+r\"\\white\\camera\\refs\", whitereffiles)\n",
    "white -= white_ref\n",
    "white = nd.gaussian_filter(white,10) # To remove texture of the reference\n",
    "\n",
    "crop([np.array(white)*(2**(8)/np.max(white))],['White reference'], callback=callback_return_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-auditor",
   "metadata": {},
   "source": [
    "Now run this to calculate the calibation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_row = (white_buffer[0]+white_buffer[1])/2\n",
    "center_col = (white_buffer[2]+white_buffer[3])/2\n",
    "# Non uniformity :\n",
    "white_norm = white_nonunif(white, center_row, center_col, photodiode_diam_pix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-polish",
   "metadata": {},
   "source": [
    "### Load filenames\n",
    "* Next run the following, it crawls the datapath and organises the images into catagories, ready to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_db = path_process(datapath)\n",
    "\n",
    "names_of_crop = []\n",
    "images_for_crop = []\n",
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:\n",
    "        subpath = f\"{datapath}/{key}/{pix}/oc/camera\"\n",
    "        name = f\"{key}, Pixel {pix}\"\n",
    "        image = image_for_cropping(subpath)\n",
    "\n",
    "        names_of_crop.append(name)\n",
    "        images_for_crop.append(np.array(image, dtype=np.uint8)) # Comment out if you wont use interactive cropper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-testament",
   "metadata": {},
   "source": [
    "### Crop active area\n",
    "* Most of the image is useless, so crop out for each pixel the activve area\n",
    "* Note: Please crop WITHIN pixel, ie, make sure the whole rectangle is inside the pixel, not bounding it. \n",
    "    * This is bacause we will take a mean of the image in calculations, and we don't want any edge nonsense in it\n",
    "    * We will loose some area but it's fine\n",
    "* Crop, press 'save crop size', and keep going for all pixels until 'Made it through all the tests. Printing cropped results below.' message shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-thread",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crop(images_for_crop,names_of_crop,callback=callback_return_pix_size) # Interactive cropper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9d790",
   "metadata": {},
   "source": [
    "#### OR, set same dims for all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aeb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [1090, 1440, 1271, 1567]# TL series stuff: [1090, 1440, 1271, 1567] # flo : [1049, 1426, 1242, 1571]\n",
    "for key in names_of_crop:\n",
    "    cell_borders[key] = corners\n",
    "print(cell_borders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-checkout",
   "metadata": {},
   "source": [
    "### Check crops (optional)\n",
    "* It's a good idea to run bellow, and make sure it all looks sensible. Redo them if needed. (Only if you used interactive cropper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-divorce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, key in enumerate(cell_borders.keys()):\n",
    "    rmin = cell_borders[key][0]\n",
    "    rmax = cell_borders[key][1]\n",
    "    cmin = cell_borders[key][2]\n",
    "    cmax = cell_borders[key][3]\n",
    "    \n",
    "    \n",
    "    imarr = images_for_crop[i][rmin:rmax, cmin:cmax]\n",
    "    \n",
    "    plt.imshow(imarr,vmin=0, vmax=np.mean(imarr)+3*np.std(imarr),cmap=\"inferno\")\n",
    "    plt.colorbar()\n",
    "    plt.title(names_of_crop[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-central",
   "metadata": {},
   "source": [
    "### Process\n",
    "* Finally run the last cell to do the actual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_subfolders = ['oc', 'sc', 'vsweep', 'vsweep_f', \"vsweep_b\", 'sr']\n",
    "\n",
    "# Just going to define this as a functiuon so later we can parallelise it using joblib:\n",
    "def process_one_image(key, datapath,nested_path, white_norm, ref, exposures, rmin, rmax, cmin, cmax):\n",
    "    # Open an image:\n",
    "    imarr = averager(f\"{datapath}/{nested_path}/camera\", repeat_db[key])\n",
    "    # Figure out voltage:\n",
    "    nominal_v = key.split('_')[1]\n",
    "    # Figure out source meter setting:\n",
    "    sm =  key.split('_')[0]\n",
    "\n",
    "    # Generate beam corrected cropped image + Powermeter flux:\n",
    "    flux, imarr_corrected = beam_correct(imarr, white_norm, ref, float(nominal_v), rmin, rmax, cmin, cmax)\n",
    "    \n",
    "    # Save:\n",
    "    keystr = \"{:.3f}\".format(float(nominal_v))\n",
    "    filename = f\"{sm}_{flux}_{exposures[keystr]}_\"\n",
    "    np.save(f\"{savepath}/{nested_path}/{filename}\",imarr_corrected)\n",
    "\n",
    "\n",
    "for key in path_db.keys():\n",
    "    for pix in path_db[key]:       \n",
    "        # Crop dimentions pull:\n",
    "        crop_key = f\"{key}, Pixel {pix}\"\n",
    "        rmin = cell_borders[crop_key][0]\n",
    "        rmax = cell_borders[crop_key][1]\n",
    "        cmin = cell_borders[crop_key][2]\n",
    "        cmax = cell_borders[crop_key][3]\n",
    "        \n",
    "        # Loop over all the sub measurements taken (OC, SC, etc):\n",
    "        for measurement_subfolder in measurement_subfolders:\n",
    "            try:\n",
    "                # db for which files were repeats:\n",
    "                nested_path = f\"{key}/{pix}/{measurement_subfolder}\" \n",
    "                repeat_db = image_intsweep_name_parser(f\"{datapath}/{nested_path}/camera\")\n",
    "                \n",
    "\n",
    "                # extract the exposures for filename:\n",
    "                exposures = {}\n",
    "                if os.path.isfile(f\"{datapath}/{nested_path}/camera/exposure_list.csv\"):\n",
    "                    with open(f\"{datapath}/{nested_path}/camera/exposure_list.csv\",'r') as file:\n",
    "                        reader = csv.reader(file)\n",
    "                        for row in reader:\n",
    "                            exposures[\"{:.3f}\".format(float(row[0]))] = row[1]\n",
    "                else:\n",
    "                    for nominal_v in np.arange(2.4,3.1,0.001):\n",
    "                        exposures[\"{:.3f}\".format(nominal_v)] = get_cam_exposure(f\"{datapath}/{nested_path}\")\n",
    "                        \n",
    "                # Make the directory for saving this measurement if not already there\n",
    "                if not os.path.isdir(f\"{savepath}/{nested_path}\"):\n",
    "                    os.makedirs(f\"{savepath}/{nested_path}\") # make the path\n",
    "\n",
    "                # Copy all the cvs/txt files:\n",
    "                try:\n",
    "                    copy_led_sm_data(f\"{datapath}/{nested_path}\",f\"{savepath}/{nested_path}\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # Generate dark reference\n",
    "                ref_files = find_tif(f\"{datapath}/{nested_path}/camera/refs\")\n",
    "                ref = averager(f\"{datapath}/{nested_path}/camera/refs\",ref_files)\n",
    "                print('I got this far!!')\n",
    "\n",
    "                # Looping over all the sweep params, parallel:\n",
    "                Parallel(n_jobs=num_cores)(delayed(process_one_image)(key2,datapath,nested_path, white_norm, ref, exposures, rmin, rmax, cmin, cmax) for key2 in repeat_db.keys())\n",
    "\n",
    "                # Save white cropped to same region as pixel image:\n",
    "                print('I got this far!!')\n",
    "                white_cropped = white[rmin:rmax,cmin:cmax]\n",
    "                np.save(f\"{savepath}/{key}/{pix}/white\", white_cropped)\n",
    "            except Exception as E:\n",
    "                print(E)\n",
    "\n",
    "# Save white reference parameters:\n",
    "white_exposure = get_cam_exposure(f\"{datapath}/white\")\n",
    "white_nominal_v = whitefiles[0].split('_')[1].split('=')[1]\n",
    "white_flux_scale = ledf(float(white_nominal_v))\n",
    "\n",
    "with open(f\"{savepath}/white_params.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Exposure', white_exposure])\n",
    "    writer.writerow(['Flux scale', white_flux_scale])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-fifth",
   "metadata": {},
   "source": [
    "### How is the data saved?\n",
    "\n",
    "* Following save format is used:\n",
    "\n",
    "```\n",
    "Root_save_folder  \n",
    "│   \n",
    "│   white_params.csv\n",
    "│   \n",
    "└───Substrate_1\n",
    "│   └───2 \n",
    "│   │   │   white.npy\n",
    "│   │   └───oc\n",
    "│   │   │   │   LED_power_suply.csv\n",
    "│   │   │   │   source_meter.csv\n",
    "│   │   │   │   camera_setting_dump.txt\n",
    "│   │   │   │   exposure_list.csv\n",
    "│   │   │   │   OC_1.027180771003644e+17_.npy\n",
    "│   │   │   │   OC_1.273380059086228e+16_.npy\n",
    "│   │   │   │   ...\n",
    "│   │   │\n",
    "│   │   └───sc\n",
    "│   │   │   │   ...\n",
    "│   │   │\n",
    "│   │   └───vsweep  \n",
    "│   │   │   │   source_meter.csv\n",
    "│   │   │   │   camera_setting_dump.txt\n",
    "│   │   │   │   0.000_1.3184070393385995e+17_.npy\n",
    "│   │   │   │   0.050_1.3184070393385995e+17_.npy\n",
    "│   │   │\n",
    "│   │   │...\n",
    "│   │\n",
    "│   │...     \n",
    "│\n",
    "└───Substrate_2\n",
    "    │   ...\n",
    "     ...\n",
    "\n",
    "```\n",
    "\n",
    "* white_params.csv holds the LED flux and exposure time used for the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
